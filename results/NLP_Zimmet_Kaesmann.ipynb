{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdaadc5-0843-4b24-885b-2c6af581925d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# NLP Projektarbeit WiSe 2024/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4c965-4c76-4ad5-9716-6a443d3eef94",
   "metadata": {},
   "source": [
    "Luca Kaesmann & Michael Zimmet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc65c40-ae8c-47dc-b79b-0f1f228e5904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dcb9a-a77d-4def-a9d6-d64f728a6f26",
   "metadata": {},
   "source": [
    "Eines der zentralen Themen im Bereich der Künstlichen Intelligenz ist die Verarbeitung von natürlicher Sprache, dabei handelt es sich um die Interaktion zwischen Computer und menschlicher Sprache. Ein Teilgebiet hiervon beschäftigt sich mit dem Question Answering, also dem Beantworten gezielter Fragen auf Basis eines gegebenen Textkontextes. Ein typischer Ansatz ist dabei ein Transformer-Modell mithilfe eines spezifischen Datensatzes zu optimieren. Dies wird als fine-tuning bezeichnet. Mit dem Aufkommen leistungsstarker Large Language Models, ist es jedoch nicht mehr notwendig Transformer-Modelle zu optimieren, da Large Language Models ohne Optimierung und mit geziehlten Prompt-Templates das Question Answering bewerkstelligen können. Ziel dieser Studienarbeit ist es 2 solcher Transformer-Modelle (DistilBERT und T5) eigens zu fine-tunen und diese mit den vortrainierten Large Language Models (ChatGPT und LLAMA 2) gegenüberzustellen. Durch die Gegenüberstellung der Modelle kann die Leistungsfähigkeit beider Ansätze verglichen werden. Dies sollte Rückschlüsse in Bezug auf die Genaugikeit, Flexibilität und Effizienz geben. Für das Question Answering soll der SQuAD Datensatz herangezogen werden und anhand des F1-Scores, sowie des Exact Match Scores eine Bewertung der Modelle abgegeben werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0075d-74fd-477e-aed9-9d6340bbb252",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Projektplanung und Vorgehen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294656ba-e5f2-4af0-9d67-58750c5b5ae7",
   "metadata": {},
   "source": [
    "In diesem Abschnitt wird kurz das Vorgehen während der Studienarbeit beschrieben. Zunächst machte sich jeder mit der Aufgabenstellung vertraut und beschäftigte sich mit grundlegenden Aspekten wie der Beschaffung des Datensatzes und der Modelle. Da sich die Studienarbeit mit dem Gegenüberstellen von Transformer-Modellen und Large Language Models beschäftigt, erfolgte ebenso die Aufteilung der Arbeit nach den Modelltypen. Einerseits musste somit das fine-tuning für zwei Transformermodelle mit anschließender Evaluierung implementiert werden und andererseits die programmatische Erstellung der Prompts, welche an die zwei Large Language Models übergeben werden, mit anschließender Evaluierung implementiert werden. Bei der Evaluierung der Modelle wurde der Exact Match Score und der F1 Score herangezogen. Diese Aufgabenteilung ermöglichte das parallele und unabhängige bearbeiten der Aufgaben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bd930-1661-41e4-a028-692fdad9ea6c",
   "metadata": {},
   "source": [
    "## 3. Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c17f47f-2fc4-45d8-b463-0ad1b9067b0c",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e26e4b-b823-4d03-94f3-5f37235479e1",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/jovyan/.local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /home/jovyan/.local/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /home/jovyan/.local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jovyan/.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: datasets in /home/jovyan/.local/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/jovyan/.local/lib/python3.11/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/.local/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/.local/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user torch torchvision torchaudio\n",
    "!pip3 install --user datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b778f-08d0-4362-ae0a-829ce4285a53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### Import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9d80f29-5558-4b5e-8ad8-739c25b1cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading, saving and loading the dataset\n",
    "import datasets\n",
    "import json\n",
    "\n",
    "# Handling the models and data\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "from transformers import T5ForQuestionAnswering\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8680c7-9238-45fa-8a74-68a3420ffefa",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Get the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0305c77-9002-4d5e-852c-ce2164389044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c7eaadf3fe45a998f550504e1d92d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960c2b42088844b1bdee69b37e054639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01739944d324c6aa79086536311d128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f7a2f31bed46c7be1f387586a6f3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b2d8586a2240a8b8da38220f32774d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"rajpurkar/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c763bddc-10e6-4bf5-829e-fe2d621b5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537f0c675bcc4502adbad58bbe3eea22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb427bce1124989ace61f7285f11c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"./squad/squad_1_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3330f577-6383-447c-92a9-5393f027ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk(\"./squad/squad_1_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f01501-149b-45d0-98f7-d2d596050f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a763ce-79e2-481f-ae27-93ec7af4cb63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2edf6d-3a2e-47a2-8b3a-571520629bec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get the relevat information from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289c1bfb-763b-459d-a25a-85fc0d76cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    for article in data:\n",
    "        contexts.append(article[\"context\"])\n",
    "        questions.append(article[\"question\"])\n",
    "\n",
    "        # the answer is saved in a list. The list cause issues in the future so it will be resolved into a string\n",
    "        answer_dict = {\"text\": article[\"answers\"][\"text\"][0], \"answer_start\": article[\"answers\"][\"answer_start\"][0]}\n",
    "        answers.append(answer_dict)\n",
    "\n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f6e55f-b3d6-40c2-acb7-3e266adfd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts, train_questions, train_answers = prepare_data(train_ds)\n",
    "test_contexts, test_questions, test_answers = prepare_data(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58f8e02-28fd-447d-a4a2-e574e81bc31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "{'text': 'Saint Bernadette Soubirous', 'answer_start': 515}\n"
     ]
    }
   ],
   "source": [
    "print(train_contexts[0])\n",
    "print(train_questions[0])\n",
    "print(train_answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b6921-7405-4332-9e7a-c0810b441be9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get the end of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab0024a-2cd6-43e5-b4d1-cc80cebe37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_index(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        true_answer = answer[\"text\"]\n",
    "        start_index = answer[\"answer_start\"]\n",
    "        end_index = start_index + len(true_answer)\n",
    "\n",
    "        if context[start_index:end_index] == true_answer:\n",
    "            answer[\"answer_end\"] = end_index\n",
    "        else:\n",
    "            for n in [1,2]:\n",
    "                if context[start_index-n:end_index-n] == true_answer:\n",
    "                    answer[\"answer_start\"] = start_index\n",
    "                    answer[\"answer_end\"] = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6dc30c-779d-417a-bc9a-308c20aadc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_end_index(train_answers, train_contexts)\n",
    "get_end_index(test_answers, test_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c59a194b-ae4b-45d6-a480-95f209549672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'September 1876', 'answer_start': 248, 'answer_end': 262}, {'text': 'twice', 'answer_start': 441, 'answer_end': 446}, {'text': 'The Observer', 'answer_start': 598, 'answer_end': 610}, {'text': 'three', 'answer_start': 126, 'answer_end': 131}, {'text': '1987', 'answer_start': 908, 'answer_end': 912}]\n",
      "[{'text': '\"golden anniversary\"', 'answer_start': 487, 'answer_end': 507}, {'text': 'February 7, 2016', 'answer_start': 334, 'answer_end': 350}, {'text': 'American Football Conference', 'answer_start': 133, 'answer_end': 161}, {'text': '\"golden anniversary\"', 'answer_start': 487, 'answer_end': 507}, {'text': 'American Football Conference', 'answer_start': 133, 'answer_end': 161}]\n"
     ]
    }
   ],
   "source": [
    "print(train_answers[5:10])\n",
    "print(test_answers[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fd9ed-dafb-4a6f-8d62-7e6eab399563",
   "metadata": {},
   "source": [
    "### Utility Operations and Funcitons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6bc5d-7a72-4c67-a1a8-fd93a386d4c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Setting up some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b4baff2-b5ec-4162-adf5-c5af7c3b1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda5_device = torch.device(\"cuda:5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f87ee4-b303-4869-80a7-d62681afa551",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Add token position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69ce215-d3ff-4660-8357-0c8583410d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_postition(encodings, answers, tokenizer):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i][\"answer_start\"]))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i][\"answer_end\"]))\n",
    "\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        go_back = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i][\"answer_end\"]-go_back)\n",
    "            go_back += 1\n",
    "\n",
    "        encodings.update({\n",
    "            \"start_positions\": start_positions,\n",
    "            \"end_positions\": end_positions\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f7e2f-fca1-4eb9-8731-107a37001849",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ac9f80-2316-44e0-8f06-2c89dac5fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoding):\n",
    "        self.encodings = encoding\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82f1ab-effe-44a8-900f-6f681e754970",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Loop to evaluate a dataset with a given model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "918d00e7-08b1-4f9b-ab2e-07d03c0ae8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a tokenizer and a model and gets the Accuracy and F1-Score of the give dataset\n",
    "f1_scores = []\n",
    "em_scores = []\n",
    "\n",
    "def evaluate_dataset(model, tokenizer, dataset, contexts, questions):\n",
    "    for i in tqdm(range(0, len(dataset), 1)):\n",
    "        # get the gold answer tokens\n",
    "        gold_start = dataset[i][\"start_positions\"].item()\n",
    "        gold_end = dataset[i][\"end_positions\"].item()\n",
    "\n",
    "        gold_answer = dataset[i][\"input_ids\"][gold_start:gold_end]\n",
    "        # get the prediction\n",
    "        with torch.no_grad():\n",
    "            model_inputs = tokenizer(contexts[i], questions[i], return_tensors=\"pt\", padding=True).to(cuda5_device)\n",
    "            input_ids = model_inputs[\"input_ids\"].to(cuda5_device)\n",
    "            attention_mask = model_inputs[\"attention_mask\"].to(cuda5_device)\n",
    "\n",
    "            if input_ids.size()[-1] > 512:\n",
    "                continue\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            start_pred = torch.argmax(outputs[\"start_logits\"], dim=1)\n",
    "            end_pred = torch.argmax(outputs[\"end_logits\"], dim=1)\n",
    "            pred_answer = input_ids[0][start_pred.item():end_pred.item()]\n",
    "\n",
    "        em_scores.append(gold_answer.tolist() == pred_answer.tolist())\n",
    "\n",
    "        # calculate f1-score and acc:\n",
    "        f1_score = compute_f1(gold_answer, pred_answer)\n",
    "        f1_scores.append(f1_score)\n",
    "\n",
    "    return f1_scores, em_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841d816-0541-4dd4-bdd0-a82a47bf3261",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get an answer from a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0afa8c00-2e31-433b-9d1b-30123539964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(context, question, model, tokenizer):\n",
    "    inputs = tokenizer(context, question, return_tensors=\"pt\", padding=True).to(cuda5_device)\n",
    "    with torch.no_grad():\n",
    "        input_ids = inputs[\"input_ids\"].to(cuda5_device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(cuda5_device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_pred = torch.argmax(outputs[\"start_logits\"], dim=1)\n",
    "        end_pred = torch.argmax(outputs[\"end_logits\"], dim=1)\n",
    "\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_pred:end_pred]))\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aed496-ee4c-4e52-b121-b4c33e78b740",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Compute the f1 score of a gold answer and a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7c663d-f6de-469b-84b2-bbabfca0dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(gold, pred):\n",
    "    gold = gold.tolist()\n",
    "    pred = pred.tolist()\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred) == 0 or len(gold) == 0:\n",
    "        return int(pred == gold)\n",
    "\n",
    "    common_tokens = set(pred) & set(gold)\n",
    "  \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "  \n",
    "    prec = len(common_tokens) / len(pred)\n",
    "    rec = len(common_tokens) / len(gold)\n",
    "  \n",
    "    return round(2 * (prec * rec) / (prec + rec), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c65ce-e41b-419d-be27-25da8a0451d8",
   "metadata": {},
   "source": [
    "### DistilBERT for Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81540d-129e-4662-97df-d529fe51c3bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db38f2c7-b347-45db-a1a3-9f8c8a3a9d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# plain model and tokenizer from pretrained\n",
    "distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b59e6819-bb46-42a9-9f63-2859119a5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_train_encodings = distilbert_tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "distilbert_test_encodings = distilbert_tokenizer(test_contexts, test_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e13bbd-e964-494d-a1d4-0975490cdad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff72ae88-5fc4-4d52-86c9-8ef7516c28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end token of the answer\n",
    "add_token_postition(distilbert_train_encodings, train_answers, distilbert_tokenizer)\n",
    "add_token_postition(distilbert_test_encodings, test_answers, distilbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac128e7-95f4-482a-bfad-797a50d5bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset object\n",
    "distilbert_train_dataset = SquadDataset(distilbert_train_encodings)\n",
    "distilbert_test_dataset = SquadDataset(distilbert_test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8c39039-218b-4ce9-abd8-15b3f3c8a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model to the device and set an opimizer\n",
    "distilbert_model.to(cuda5_device)\n",
    "distilbert_model.train()\n",
    "distitlbert_optim = torch.optim.AdamW(distilbert_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce0c3267-865a-4519-802a-ecb61a2e1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainloader Object\n",
    "train_loader = DataLoader(distilbert_train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bb917a6-ad35-495e-b9cb-24a7b5813265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0a6adad-7a28-4023-b04f-9e9f14bea25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1369/1369 [14:19<00:00,  1.59it/s, loss=1.58] \n",
      "Epoch 1: 100%|██████████| 1369/1369 [14:21<00:00,  1.59it/s, loss=0.885]\n",
      "Epoch 2: 100%|██████████| 1369/1369 [14:19<00:00,  1.59it/s, loss=0.76] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    # this is for the visualisation of the progress with tqdm\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        distitlbert_optim.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(cuda5_device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(cuda5_device)\n",
    "        start_positions = batch[\"start_positions\"].to(cuda5_device)\n",
    "        end_positions = batch[\"end_positions\"].to(cuda5_device)\n",
    "\n",
    "        outputs = distilbert_model(input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        distitlbert_optim.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70cc2ba2-bd37-40a2-bd78-3d14220327f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/distilbert_kaesmann_zimmet/tokenizer_config.json',\n",
       " 'model/distilbert_kaesmann_zimmet/special_tokens_map.json',\n",
       " 'model/distilbert_kaesmann_zimmet/vocab.txt',\n",
       " 'model/distilbert_kaesmann_zimmet/added_tokens.json',\n",
       " 'model/distilbert_kaesmann_zimmet/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "distilbert_model_path = \"model/distilbert_kaesmann_zimmet\"\n",
    "distilbert_model.save_pretrained(distilbert_model_path)\n",
    "distilbert_tokenizer.save_pretrained(distilbert_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf70bf-b605-48ba-ad69-38677e0cb915",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47a42cf1-2657-4da1-bee0-b42e631e2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer from the disk\n",
    "distilbert_trained_model = DistilBertForQuestionAnswering.from_pretrained(\"model/distilbert_kaesmann_zimmet/\", local_files_only=True)\n",
    "distilbert_trained_tokenizer = DistilBertTokenizerFast.from_pretrained(\"model/distilbert_kaesmann_zimmet/\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c663712-9018-4a67-b155-5b4e092a6dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trained_model.eval()\n",
    "distilbert_trained_model.to(cuda5_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "96b2f88a-0b20-41c4-ac15-5ba601265a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:42<00:00, 248.07it/s]\n"
     ]
    }
   ],
   "source": [
    "distilbert_f1_scores, distilbert_em_scores = evaluate_dataset(distilbert_trained_model, distilbert_trained_tokenizer, distilbert_test_dataset, test_contexts, test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d6cdc95-efb7-4c52-9a9f-970381dae396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7132413924291433\n",
      "0.5715236827087693\n"
     ]
    }
   ],
   "source": [
    "print(sum(distilbert_f1_scores) / len(distilbert_f1_scores))\n",
    "print(sum(distilbert_em_scores) / len(distilbert_em_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad508b-0024-4e3b-b694-d4699f83935a",
   "metadata": {},
   "source": [
    "### T5 for Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1a1c5-1b05-4f25-8686-f6fe19e80947",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e62a50ce-6546-41d6-9874-4181e3e8b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained models\n",
    "t5_tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "t5_model = T5ForQuestionAnswering.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52513a0c-250e-4039-895f-ede4058f87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_train_encodings = t5_tokenizer(train_contexts, train_questions, padding=True)\n",
    "t5_test_encodings = t5_tokenizer(test_contexts, test_questions, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c08548f2-64e0-46c1-9180-340c9397785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "208853fb-92cf-4633-b88f-bcd58a6df192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the token positions of the answer\n",
    "add_token_postition(t5_train_encodings, train_answers, t5_tokenizer)\n",
    "add_token_postition(t5_test_encodings, test_answers, t5_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e491d9-9f7f-46c9-bb9a-8d62b3a66bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "t5_train_dataset = SquadDataset(t5_train_encodings)\n",
    "t5_test_dataset = SquadDataset(t5_test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fbce5cd-2b67-47bc-8946-302d46d1606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model to the device and set a optimizer\n",
    "t5_model.to(cuda5_device)\n",
    "t5_model.train()\n",
    "t5_optim = torch.optim.AdamW(t5_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "005a1a1f-12cd-41fc-a41f-9453a6f6bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a trainloader object\n",
    "t5_train_loader = torch.utils.data.DataLoader(t5_train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83e51f-0f88-4534-acb7-006f241fbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████      | 8881/21900 [1:31:19<2:13:27,  1.63it/s, loss=1.2]   "
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    # this is for the visualisation of the progress with tqdm\n",
    "    loop = tqdm(t5_train_loader)\n",
    "    for batch in loop:\n",
    "        t5_optim.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(cuda5_device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(cuda5_device)\n",
    "        start_positions = batch[\"start_positions\"].to(cuda5_device)\n",
    "        end_positions = batch[\"end_positions\"].to(cuda5_device)\n",
    "\n",
    "        outputs = t5_model(input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        t5_optim.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c937c3-d71b-401a-bc3e-d4ce07ed650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model_path = \"model/t5_kaesmann_zimmet\"\n",
    "t5_model.save_pretrained(t5_model_path)\n",
    "t5_tokenizer.save_pretrained(t5_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788c9d1-8e8a-4e3f-8836-3a3fdcbd72c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ddeb9e-46e2-4d31-8633-cd1b05130ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model from the disk\n",
    "t5_trained_model = T5ForQuestionAnswering.from_pretrained(\"model/t5_kaesmann_zimmet/\", local_files_only=True)\n",
    "t5_trained_tokenizer = T5TokenizerFast.from_pretrained(\"model/t5_kaesmann_zimmet/\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b3ed758-1d67-497c-a384-7bf8a814dc85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForQuestionAnswering(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to eval mode and move to device\n",
    "t5_trained_model.eval()\n",
    "t5_trained_model.to(cuda5_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb571a8a-c903-4165-943f-1593dc773ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the t5 encodings, add the token positions of the answers and create a dataset object\n",
    "t5_test_encodings = t5_trained_tokenizer(test_contexts, test_questions, padding=True)\n",
    "add_token_postition(t5_test_encodings, test_answers, t5_trained_tokenizer)\n",
    "t5_test_dataset = SquadDataset(t5_test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09379adc-8f90-4ab0-9b3e-5b9682d747f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [04:40<00:00, 37.64it/s]\n"
     ]
    }
   ],
   "source": [
    "t5_f1_scores, t5_em_scores = evaluate_dataset(t5_trained_model, t5_trained_tokenizer, t5_test_dataset, test_contexts, test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2d9d86-3bdb-4e13-b34c-51fffe503289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933860970725666\n",
      "0.6476926010678871\n"
     ]
    }
   ],
   "source": [
    "print(sum(t5_f1_scores) / len(t5_f1_scores))\n",
    "print(sum(t5_em_scores) / len(t5_em_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0714bd1-5fce-4146-9277-c9d4371c563c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Check the model before it was finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e1701-6d49-4dff-9748-2331bf793bb5",
   "metadata": {},
   "source": [
    "This is just a validation of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "275a44e5-bfad-4903-983b-7b922e9875d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_plain_model = T5ForQuestionAnswering.from_pretrained(\"t5-base\")\n",
    "t5_plain_tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e042062-0776-46f6-afc8-aeab3e382a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForQuestionAnswering(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_plain_model.eval()\n",
    "t5_plain_model.to(cuda5_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bf23bcf-0826-4066-a39d-9d7a99111216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the t5 encodings, add the token positions of the answers and create a dataset object\n",
    "t5_test_encodings = t5_plain_tokenizer(test_contexts, test_questions, padding=True)\n",
    "add_token_postition(t5_test_encodings, test_answers, t5_plain_tokenizer)\n",
    "t5_test_dataset = SquadDataset(t5_test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87ff3e80-eb33-4adc-9b3e-6a37d72c7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 4154/10570 [01:52<01:53, 56.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4189/10570 [01:53<02:05, 50.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4203/10570 [01:53<02:02, 51.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4284/10570 [01:55<01:27, 72.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4299/10570 [01:55<01:35, 65.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4603/10570 [02:03<02:03, 48.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4861/10570 [02:10<02:07, 44.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5454/10570 [02:26<02:11, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 5663/10570 [02:31<01:51, 43.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 6230/10570 [02:47<01:30, 48.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6384/10570 [02:51<01:32, 45.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n",
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 7339/10570 [03:17<01:26, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contunuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [04:46<00:00, 36.87it/s]\n"
     ]
    }
   ],
   "source": [
    "t5_plain_f1_scores, t5_plain_em_scores = evaluate_dataset(t5_plain_model, t5_plain_tokenizer, t5_test_dataset, test_contexts, test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "985751d7-35c5-4dc9-80cc-337712bf35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09862863966197859\n",
      "0.04473224947184716\n"
     ]
    }
   ],
   "source": [
    "print(sum(t5_plain_f1_scores) / len(t5_plain_f1_scores))\n",
    "print(sum(t5_plain_em_scores) / len(t5_plain_em_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbcb9e-628c-4dff-9bc8-aa1b4cd38e0e",
   "metadata": {},
   "source": [
    "##### Distilbert on TD-B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a923b81-ae29-4220-8733-c8da17385214",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TD-B dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282941e-8924-41e5-b783-63f8e7afcd52",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec46796c-8e2b-4e4c-8b5b-be33c52bc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file for reading\n",
    "with open('TD_B.txt', 'r') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Convert the string to a Python list\n",
    "ids_list = eval(content)  # Safely evaluate the string as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcca3aff-a9e6-4b77-a051-7877f1a42d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "td_b = []\n",
    "\n",
    "for entry in test_ds:\n",
    "    if entry[\"id\"] in ids_list:\n",
    "        td_b.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad32b7-ce8d-4a2d-9035-4cd26a349533",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e50d136-e615-4fc2-9768-87af252d79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_b_contexts, td_b_questions, td_b_answers = prepare_data(td_b)\n",
    "get_end_index(td_b_answers, td_b_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a1cc6-62a6-40dd-ade9-83791625eedc",
   "metadata": {},
   "source": [
    "#### TD-B mit Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93a137c3-8b1a-4616-b843-8943e3d117cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_td_b_encodings = distilbert_trained_tokenizer(td_b_contexts, td_b_questions)\n",
    "add_token_postition(distilbert_td_b_encodings, td_b_answers, distilbert_trained_tokenizer)\n",
    "distilbert_td_b_dataset = SquadDataset(distilbert_td_b_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ca8d41a-3410-4d58-8239-5462d1b04ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 198.52it/s]\n"
     ]
    }
   ],
   "source": [
    "distilbert_td_b_f1_scores, distilbert_td_b_em_scores = evaluate_dataset(distilbert_trained_model, distilbert_trained_tokenizer, distilbert_td_b_dataset, td_b_contexts, td_b_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db2803c8-b154-46ae-97b5-e7723468b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7687500000000003\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "print(sum(distilbert_td_b_f1_scores) / len(distilbert_td_b_f1_scores))\n",
    "print(sum(distilbert_td_b_em_scores) / len(distilbert_td_b_em_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe929d3-4841-4855-8442-fed919a8b1aa",
   "metadata": {},
   "source": [
    "#### TD-B mit T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c5876d-b858-4f59-8361-f814cfb6c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_td_b_encodings = t5_trained_tokenizer(td_b_contexts, td_b_questions, padding=True)\n",
    "add_token_postition(t5_td_b_encodings, td_b_answers, t5_trained_tokenizer)\n",
    "t5_tdb_dataset = SquadDataset(t5_td_b_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f96c46f-f91b-4a31-b0fd-9fe1bab7c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.98it/s]\n"
     ]
    }
   ],
   "source": [
    "t5_td_b_f1_scores, t5_td_b_em_scores = evaluate_dataset(t5_trained_model, t5_trained_tokenizer, t5_tdb_dataset, td_b_contexts, td_b_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77d04b4b-df20-4665-ab01-e4aae607a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "print(sum(t5_td_b_f1_scores) / len(t5_td_b_f1_scores))\n",
    "print(sum(t5_td_b_em_scores) / len(t5_td_b_em_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cddad-5e99-4b99-be22-e9dc0783167d",
   "metadata": {},
   "source": [
    "#### Get answers on TD-B with Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "925a2c3e-aa57-4784-8d0a-89cb5ddc1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_answers_td_b = {}\n",
    "\n",
    "for i in range (0, len(td_b_questions), 1):\n",
    "    context = td_b_contexts[i]\n",
    "    question = td_b_questions[i]\n",
    "    gold_answer = td_b_answers[i][\"text\"]\n",
    "    pred_answer = get_answer(context, question, distilbert_trained_model, distilbert_trained_tokenizer)\n",
    "    distilbert_answers_td_b[i] = {\n",
    "        \"context\": context,\n",
    "        \"question\": question,\n",
    "        \"gold_answer\": gold_answer,\n",
    "        \"pred_answer\": pred_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def4b51-e22a-48ee-8053-2932d8faca08",
   "metadata": {},
   "source": [
    "#### Get answers in TD-B with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9d2b102-4a00-4668-9bab-bd126c14854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_answers_td_b = {}\n",
    "\n",
    "for i in range (0, len(td_b_questions), 1):\n",
    "    context = td_b_contexts[i]\n",
    "    question = td_b_questions[i]\n",
    "    gold_answer = td_b_answers[i][\"text\"]\n",
    "    pred_answer = get_answer(context, question, t5_trained_model, t5_trained_tokenizer)\n",
    "    t5_answers_td_b[i] = {\n",
    "        \"context\": context,\n",
    "        \"question\": question,\n",
    "        \"gold_answer\": gold_answer,\n",
    "        \"pred_answer\": pred_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4783a4de-421d-4013-9cf3-d0e53df12d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.',\n",
       " 'question': 'Who did the Panthers beat in the NFC Championship Game?',\n",
       " 'gold_answer': 'Arizona Cardinals',\n",
       " 'pred_answer': 'Arizona Cardinal'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_answers_td_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40cfb58f-71a3-4981-96f1-8ab06c7fd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionaries as json files\n",
    "with open(\"distilbert_answers.json\", \"w\") as outfile: \n",
    "    json.dump(distilbert_answers_td_b, outfile)\n",
    "\n",
    "with open(\"t5_answers.json\", \"w\") as outfile: \n",
    "    json.dump(t5_answers_td_b, outfile)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Large Language Models for Question Answering\n",
    "\n",
    "The complete process for question answering using the large language models (ChatGPT, LLAMA) is described below.\n",
    "Due to the pricing of ChatGPT, the prompts had to be transferred manually via the web interface.\n",
    "\n",
    "Important files:\n",
    "1. prompts_1.txt, prompts_2.txt -> contain the prepared prompts for the models\n",
    "2. answers_1_gpt.txt, answers_2_gpt.txt -> contain the answers for ChatGPT \n",
    "3. answers_1_lama.txt, answers_2_lama.txt -> contain the answers for LLAMA"
   ],
   "id": "7abc3753aee6ffb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get SQuAD Dataset",
   "id": "c527ba833c1dfc8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:29.420911Z",
     "start_time": "2024-11-28T14:20:29.417964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def download_squad_dataset() -> None:\n",
    "    splits = {'train': 'plain_text/train-00000-of-00001.parquet',\n",
    "              'validation': 'plain_text/validation-00000-of-00001.parquet'}\n",
    "\n",
    "    test_df = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"train\"])\n",
    "    validation_df = pd.read_parquet(\"hf://datasets/rajpurkar/squad/\" + splits[\"validation\"])\n",
    "\n",
    "    test_df.to_json('squad_test_data.json')\n",
    "    validation_df.to_json('squad_validation_data.json')"
   ],
   "id": "fe5be779955091a9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:31.006834Z",
     "start_time": "2024-11-28T14:20:31.004396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_squad_dataset() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    test_df = pd.read_json('squad_test_data.json')\n",
    "    val_df = pd.read_json('squad_validation_data.json')\n",
    "    return test_df, val_df"
   ],
   "id": "d18e6a141ad3ec26",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:31.847190Z",
     "start_time": "2024-11-28T14:20:31.842906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_random_batch(n: int, dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    #set random_state to always get the same dataset\n",
    "    return dataframe.sample(n=n, random_state=42)"
   ],
   "id": "84fe0f8ff27dabd7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:37.258592Z",
     "start_time": "2024-11-28T14:20:35.982940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# only use the download_squad_dataset() function below once at the beginning\n",
    "#download_squad_dataset()\n",
    "test_df, validation_df = load_squad_dataset()\n",
    "\n",
    "# original TD-B dataset\n",
    "validation_batch = create_random_batch(100, validation_df)\n",
    "\n",
    "# This ids are the ids used in the below code block from TD_B.txt\n",
    "ids = validation_batch[\"id\"].tolist()"
   ],
   "id": "1ece064788795e79",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Generation",
   "id": "2c02e3cfdcc16307"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:38.838241Z",
     "start_time": "2024-11-28T14:20:38.836051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from typing import List"
   ],
   "id": "504d148c3e0ce723",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:40.081377Z",
     "start_time": "2024-11-28T14:20:40.077227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_prompts(dataframe: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generates a List based on a prompt-template out of the given dataframe\n",
    "    :param dataframe: squad dataset as pandas dataframe\n",
    "    :return: List of prepared prompts\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = ('Can you answer me the following question \"%1\" based on the following context \"%2\"? Please structure your answer always in the same format like '\n",
    "                       'Question \":\" Answer\". Dont output long Instruction just the answer as short as possible. If its possible only with one word/phrase')\n",
    "\n",
    "    prompts = []\n",
    "    for i in dataframe.itertuples():\n",
    "        #prepare question and context to avoid multiline prompts\n",
    "        question = i.question.strip().replace('\\n', ' ')\n",
    "        context = i.context.strip().replace('\\n', ' ')\n",
    "        \n",
    "        # add question and context to the prompt-template\n",
    "        prompt = prompt_template.replace('%1', question).replace('%2', context)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    return prompts"
   ],
   "id": "73fe0b0133e0e2e4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:42.093095Z",
     "start_time": "2024-11-28T14:20:42.090579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_data_to_file(data: List[str], file_name:str) -> None:\n",
    "    with open(file_name, \"w\") as file:\n",
    "        for i in data:\n",
    "            file.write(i + \"\\n\")"
   ],
   "id": "a7b9d71d9c8d1462",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:20:43.438580Z",
     "start_time": "2024-11-28T14:20:43.433416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = generate_prompts(validation_batch)\n",
    "write_data_to_file(prompts, 'LLM_Results/second_atempt/prompts_2.txt')"
   ],
   "id": "dd583fb5a619d372",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Processing for LLAMA",
   "id": "9ab92bdb2393cbc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:33.750140Z",
     "start_time": "2024-11-28T14:21:33.747657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_prompts(file_name: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Reads the prompts from a file and returns them as a list\n",
    "    :param file_name: prompts file\n",
    "    :return: List of prompts\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r') as f:\n",
    "        prompts = f.readlines()\n",
    "\n",
    "    return prompts"
   ],
   "id": "310d29e7b00ca50d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompts = load_prompts('prompts_2.txt')\n",
    "\n",
    "answers = []\n",
    "count = 1\n",
    "print('Start')\n",
    "for i in prompts:\n",
    "    # Tokenize the prompt into a for the model suitable format ('pt' = pytorch tensor)\n",
    "    inputs = tokenizer(i, return_tensors=\"pt\")\n",
    "\n",
    "    #Generate the answer\n",
    "    outputs = model.generate(inputs['input_ids'],\n",
    "                             num_return_sequences=1,                # Limit the Answers to one\n",
    "                             pad_token_id=tokenizer.eos_token_id)   # Use end of sequence token as padding\n",
    "    \n",
    "    # Decode back to readable text\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answers.append(response.strip().replace('\\n', ''))\n",
    "    \n",
    "    # Monitor the progress\n",
    "    print(count, ' = ', response)\n",
    "    count += 1\n",
    "\n",
    "    write_data_to_file(answers, 'answers_2_lama.txt')"
   ],
   "id": "bd4160af53d2a8a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When using the Large Language Models LLAMA, a massive amount of computing time was required during the first try.  \n",
    "The model required more than 5 hours to process the 100 prepared prompts from the TD-B data set. Likewise, the  \n",
    "quality of the answers left a lot to be desired, as the questions was not always answered using the attached context.   \n",
    "However, after the prompt template was revised again, this problem was reduced to a minimum. In general,  \n",
    "there were no serious problems in connection with the Large Language Models."
   ],
   "id": "cae320d00198f1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation for both Models",
   "id": "1215e038f88d5084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:38.929156Z",
     "start_time": "2024-11-28T14:21:38.926653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "import datasets"
   ],
   "id": "864e52dcfb65c289",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:41.691858Z",
     "start_time": "2024-11-28T14:21:41.689227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_answers(file: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Opens a file and reads the answers line by line into a list\n",
    "    :param file: answers file\n",
    "    :return: List containing the answers\n",
    "    \"\"\"\n",
    "    with file.open('r') as f:\n",
    "        answers = f.readlines()\n",
    "\n",
    "    return answers"
   ],
   "id": "db39ed5952393de4",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:43.226991Z",
     "start_time": "2024-11-28T14:21:43.224112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_exact_match_score(answers_file: Path, dataset: datasets) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the exact match score over a while dataset\n",
    "    :param answers_file: File containing the answers (one answer per line)\n",
    "    :param dataset: original dataset for the real answers\n",
    "    :return: exact match score\n",
    "    \"\"\"\n",
    "    td_b_answers = load_answers(answers_file)\n",
    "\n",
    "    exact_matches = 0\n",
    "    \n",
    "    # iterate over both lists and compare the answers\n",
    "    for i, j in zip(dataset['answers'], td_b_answers):\n",
    "        answers = i['text']\n",
    "        \n",
    "        #every answer has the following format \"Answer: answer\"\n",
    "        answer_model = j.split(':', maxsplit=1)[1].strip()\n",
    "\n",
    "        if answer_model.lower() in (answer.lower() for answer in answers):\n",
    "            exact_matches += 1\n",
    "\n",
    "    exact_match_score = exact_matches / len(td_b)\n",
    "    return exact_match_score"
   ],
   "id": "eaed1ea854f1ea9a",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:46.570863Z",
     "start_time": "2024-11-28T14:21:46.567769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_f1_score(answers_file: Path, dataset: datasets) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the f1 score over a whole dataset\n",
    "    :param answers_file: File containing the answers (one answer per line)\n",
    "    :param dataset: original dataset for the real answers\n",
    "    :return: f1 score\n",
    "    \"\"\"\n",
    "    td_b_answers = load_answers(answers_file)\n",
    "    f1_scores = []\n",
    "\n",
    "    for i, j in zip(dataset['answers'], td_b_answers):\n",
    "        answers = [answer.lower() for answer in i['text']]\n",
    "        answer_model = j.split(':', maxsplit=1)[1].strip().lower()\n",
    "\n",
    "        f1 = 0\n",
    "        # calc the highest f1 score for each possible answer (every answer has various choices)\n",
    "        for item in answers:\n",
    "            f1 = max(f1, calc_single_f1_score(answer_model, item))\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # calculate the average f1 score over all answers\n",
    "    final_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "    return final_f1_score"
   ],
   "id": "8305a6459f742c32",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The F1-Score is a metric that combines the precision and recall of a model. It is calculated by the following formular:  \n",
    "   \n",
    "<div style=\"text-align: center\">\n",
    "$Precision = \\frac{TP}{TP + FP}$\n",
    "<br><br>\n",
    "$Recall = \\frac{TP}{TP + FN}$\n",
    "<br><br>\n",
    "$F1 = 2 \\cdot \\frac{\\text{Präzision} \\cdot \\text{Recall}}{\\text{Präzision} + \\text{Recall}}$\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- TP (True Positives): The number of equal word in the predicted answer and the real answer  \n",
    "- FP (False Positives): The number of words in the predicted answer that are not in the real answer  \n",
    "- FN (False Negatives): The number of words in the real answer that are missing in the predicted answer  "
   ],
   "id": "cc38fa8fd607115c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:51.163498Z",
     "start_time": "2024-11-28T14:21:51.155116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_single_f1_score(predicted: str, answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the f1 score for a given question\n",
    "    :param predicted: Answer predicted by the model\n",
    "    :param answer: Real answer from the dataset\n",
    "    :return: f1 score\n",
    "    \"\"\"\n",
    "    predicted_tokens = predicted.split()\n",
    "    tokens = answer.split()\n",
    "\n",
    "    # calculate basic values\n",
    "    # To find the intersection of two lists, we first convert the lists to sets and link them with the & operator\n",
    "    common_tokens = set(predicted_tokens) & set(tokens)\n",
    "    tp = len(common_tokens)             # True Positives\n",
    "    fp = len(predicted_tokens) - tp     # False Positives\n",
    "    fn = len(tokens) - tp               # False Negatives\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ],
   "id": "b6d55f313c85a2b6",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Due to problems with the answers column in the dataframe (column was a whole string which wasn't that easy to convert to a suitable dictionary)\n",
    "it was more practical to work with datasets. Important to mention hereby is that the answers for each model were generated in a specific order\n",
    "to keep this order I used list comprehension. "
   ],
   "id": "e0af9afb7a628f06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:21:58.959998Z",
     "start_time": "2024-11-28T14:21:54.115762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_dataset = load_dataset(\"rajpurkar/squad\")['validation']\n",
    "td_b = validation_dataset.select(\n",
    "    [validation_dataset['id'].index(id_) for id_ in ids if id_ in validation_dataset['id']])\n",
    "\n",
    "exact_match_gpt = calc_exact_match_score(Path('LLM_Results/second_atempt/answers_2_gpt.txt'), td_b)\n",
    "exact_match_llama = calc_exact_match_score(Path('LLM_Results/second_atempt/answers_2_lama.txt'), td_b)\n",
    "\n",
    "f1_gpt = calc_f1_score(Path('LLM_Results/second_atempt/answers_2_gpt.txt'), td_b)\n",
    "f1_llama = calc_f1_score(Path('LLM_Results/second_atempt/answers_2_lama.txt'), td_b)\n",
    "\n",
    "print('Exact Match GPT: ', exact_match_gpt)\n",
    "print('Exact Match LLAMA: ', exact_match_llama)\n",
    "print()\n",
    "print('F1 GPT: ', f1_gpt)\n",
    "print('F1 LLAMA: ', f1_llama)"
   ],
   "id": "61d8d089762ef10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match GPT:  0.81\n",
      "Exact Match LLAMA:  0.48\n",
      "\n",
      "F1 GPT:  0.9197234432234431\n",
      "F1 LLAMA:  0.5953380394115687\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "051056df-adeb-4afa-88b7-37c54bfd3dea",
   "metadata": {},
   "source": [
    "## 4. Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3354d1-7958-4918-947d-92e10d9cdf7c",
   "metadata": {},
   "source": [
    "1. Fine-tuned Modelle auf TD-A und TD-B  \n",
    "    Die fine-tuned Modelle zeigen unterschiedliche Ergebnisse, je nachdem, ob sie auf TD-A oder TD-B bewertet werden.\n",
    "    Die Ergebnisse sind in den nachstehenden Tabellen aufgeführt. Auf den größeren Datensatz TD-A performed T5 leicht\n",
    "    besser als DistilBERT, allerdings erreichen beide keine herausragend guten Ergebnisse.\n",
    "     \n",
    "2. Ist TD-B groß genug, um Rückschlüsse auf das Verhalten bei TD-A zu ziehen?  \n",
    "    Ja, TD-B lässt Rückschlüsse auf das Verhalten der Modelle auf TD-A zu, da die Datenquellen identisch sind,  \n",
    "    aber die geringe Größe von TD-B bedeutet, dass die Ergebnisse nicht die gesamte Komplexität und Vielfalt von TD-A abdecken. Daher kann eine  \n",
    "    Analyse auf TD-B einige der Herausforderungen von TD-A nicht vollständig widerspiegeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337aba12-c005-466f-982c-a87128c1b667",
   "metadata": {},
   "source": [
    "### Exact Match Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a60567-7c7a-46c6-82f6-edb7e4b3a038",
   "metadata": {},
   "source": [
    "<table border=\"1\" style=\"border-collapse: collapse; text-align: center; float: left\">\n",
    "  <tr>\n",
    "    <th>Datensatz</th>\n",
    "    <th>DistilBERT</th>\n",
    "    <th>T5</th>\n",
    "    <th>Chat GPT</th>\n",
    "    <th>LLAMA</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TD-A</td>\n",
    "    <td>57,3%</td>\n",
    "    <td>64,8%</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TD-B</td>\n",
    "    <td>59%</td>\n",
    "    <td>59%</td>\n",
    "    <td>81%</td>\n",
    "    <td>48%</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00863657-d64e-4318-8bec-380ec360f0bf",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7816197-6f50-4b53-a453-0d14d352d2b4",
   "metadata": {},
   "source": [
    "<table border=\"1\" style=\"border-collapse: collapse; text-align: center; float: left\">\n",
    "  <tr>\n",
    "    <th>Datensatz</th>\n",
    "    <th>DistilBERT</th>\n",
    "    <th>T5</th>\n",
    "    <th>Chat GPT</th>\n",
    "    <th>LLAMA</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TD-A</td>\n",
    "    <td>71,3%</td>\n",
    "    <td>79,3%</td>\n",
    "    <td>-</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TD-B</td>\n",
    "    <td>76,9%</td>\n",
    "    <td>77,9%</td>\n",
    "    <td>91%</td>\n",
    "    <td>59%</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Betrachtung verschiedener Antworten:\n",
    "#### What does increased oxygen concentrations in the patient's lungs displace:  \n",
    "\n",
    " In 1979, the Soviet Union deployed its 40th Army into Afghanistan, attempting to suppress an Islamic rebellion \n",
    " against an allied Marxist regime in the Afghan Civil War. The conflict, pitting indigenous impoverished Muslims (mujahideen)\n",
    " against an anti-religious superpower, galvanized thousands of Muslims around the world to send aid and sometimes to go\n",
    " themselves to fight for their faith. Leading this pan-Islamic effort was Palestinian sheikh Abdullah Yusuf Azzam. \n",
    " While the military effectiveness of these \"Afghan Arabs\" was marginal, an estimated 16,000 to 35,000 Muslim volunteers \n",
    " came from around the world came to fight in Afghanistan.\n",
    "\n",
    " Distilbert:     carbon monoxide from the heme group of hemoglobin  \n",
    " T5:             carbon monoxid  \n",
    " ChatGPT:        What does increased oxygen concentrations in the patient's lungs displace? : Carbon monoxide  \n",
    " LLAMA:          Answer: Displace  \n",
    " \n",
    " Gold Answer:   carbon monoxide  \n",
    " \n",
    " Kommentar: Alle modelle liefern gute Ergebnisse außer LLAMA, T5 hat allerdings \"monoxid\" statt \"monoxide\" zurückgegeben.     \n",
    "   \n",
    "  \n",
    "#### How many Muslims came from around the world to fight in Afghanistan?  \n",
    "    \n",
    "Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient \n",
    "and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the 'bends') are \n",
    "sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme \n",
    "group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial \n",
    "pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles \n",
    "of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of \n",
    "the treatment.\n",
    "  \n",
    "Distilbert:     16, 000 to 35,  \n",
    "T5:             16,000 to 3  \n",
    "ChatGPT:        How many Muslims came from around the world to fight in Afghanistan? : 16,000 to 35,000  \n",
    "LLAMA:          Answer: 16,000 to 35,000   \n",
    "\n",
    "Gold Answer:    16,000 to 35,000\n",
    "\n",
    "Kommentar: Die LLMs geben die richtige Antwort zurück. Die Transformer Modelle scheinen Probleme mit Zahlen zu haben.\n",
    "  \n",
    "#### What differs about secondary chloroplasts' membranes?  \n",
    "\n",
    " While primary chloroplasts have a double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional \n",
    " membranes outside of the original two, as a result of the secondary endosymbiotic event, when a nonphotosynthetic eukaryote engulfed \n",
    " a chloroplast-containing alga but failed to digest it—much like the cyanobacterium at the beginning of this story. The engulfed alga \n",
    " was broken down, leaving only its chloroplast, and sometimes its cell membrane and nucleus, forming a chloroplast with three or four \n",
    " membranes—the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell \n",
    " membrane.\n",
    "\n",
    " Distilbert:     double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional membranes outside of the original two  \n",
    " T5:             additional membranes outside of the original two  \n",
    " ChatGPT:        What differs about secondary chloroplasts' membranes? : They have additional membranes outside the original two.  \n",
    " LLAMA:          Answer: additional   \n",
    "\n",
    " Gold Answer:   additional membranes outside of the original two\n",
    " \n",
    " Kommentar: Bis auf LLAMA geben alle Modelle korrekte Antworten zurück."
   ],
   "id": "f032970546aec441"
  },
  {
   "cell_type": "markdown",
   "id": "89a04c3b-f7c8-4f36-b4f6-537ad7c5f154",
   "metadata": {},
   "source": [
    "## Probleme und Diskussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270049c-af14-4bef-98ee-8800dd3f0bd1",
   "metadata": {},
   "source": [
    "### Kapazität der GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385ec01-c316-4e34-8e1b-0fdad6a32d4d",
   "metadata": {},
   "source": [
    "Während dem Training des T5-Modells mit dem pretrained-Modell \"t5-base\" konnte nur eine sehr kleine Batch-Size gewählt werden. Sobald die Batch-Size auf 8 oder größer gestellt wurde gab es Probleme mit dem V-RAM der GPUs. Überraschenderweise lief dieser bei einer zu großen Batch-Size voll und das Training wurde abgebrochen. Nach dem das Training abgebrochen wurde, lagen die \"Reste\" der Tensoren noch im V-RAM der GPU. Eine Lösung, um den V-RAM aufzuräumen war der Restart des Python-Kernels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6027a17-159c-4924-a83a-d3a8e226a516",
   "metadata": {},
   "source": [
    "### Rechenleistung for LLAMA Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b7ab4-0210-4611-8b5b-0a4105d2c0d2",
   "metadata": {},
   "source": [
    "Bei der Benutzung der Large Language Models LLAMA wurde beim erstmaligen ab-\n",
    "setzen der Prompts eine massive Rechenzeit benötigt. Das Modell benötigte für die\n",
    "Bearbeitung der 100 aufbereiteten Prompts aus dem TD-B Datensatz mehr als 5 Stunden. \n",
    "Ebenso lies die Qualität der Antworten immer wieder zu wünschen übrig, da die\n",
    "Frage nicht immer mithilfe des angefügten Kontextes beantwortet wurde. Nachdem\n",
    "das Prompt-Template nochmals überarbeitet wurde, konnte dieses Problem jedoch auf\n",
    "ein Minimum reduziert werden. Im Allgemeinen ergaben sich im Zusammenhang mit\n",
    "den Large Language Models aber keine Schwerwiegenden Probleme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170fd5c-29e6-408d-91ad-c5339f9e58bf",
   "metadata": {},
   "source": [
    "### Diskussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bcf92-9e0c-42ef-b8c3-97516eb35ef3",
   "metadata": {},
   "source": [
    "Besonders für das Modell T5 gibt es weiter pretrained-Modelle neben dem \"t5-base\", welche möglicherweise eine bessere Performance liefern. Im Rahmen dieser Arbeit wurde allerding nur das vorhing genannte pretrained-Modell verwendet. Es sind einerseits Modelle in weiteren Größen vorhanden, welche unterschiedlich viel Zeit für das Training und die Evaluierung benötigen. Andererseits gibt es von den Modellen. der verschiedenen Größen auch weiterentwickelte Versionen, mit unterschiedlichen Verbesserungen in der Architektur der Modelle. Um die Performance des T5-Modells zu verbessert können verschiedene Modelle getestet werden. Diese versuche ziehen auch eine Anpassung der Hyperparameter für das Training wie die Anzahl der Epochen, Auswahl des Optimizers oder der Learning-Rate nach sich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a6af5-4954-48fc-9853-7bcac7bc15b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
